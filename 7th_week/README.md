# 第7周：Python 网络爬虫基础（上）

### 技能掌握

- 了解网络爬虫的执行流程和工作原理
- 学会 Python 中的正则表达式
- 学会 urllib 和 requests 库的使用
- 能够对 web 网页中的信息进行简单的爬取
- 了解 GET 和 POST 请求中的信息传递
- 了解爬虫中常见错误的处理



### 通关作业

> **问题描述**

本周闯关作业具体如下：

1. 分别使用 userlib 和 requests 爬取有道翻译的信息，要求输入英文后获取对应的中文翻译信息。
2. 分页爬取58同城的租房信息，信息内容要求有 “标题、图片、户型、价格”，并且获取指定页的所有租房信息（如 URL 地址：<http://bj.58.com/dashanzi/chuzu/pn1/?ClickID=1>）。
3. 爬取猫眼电影中榜单栏目中 TOP100 榜的所有电影信息（10页信息全部爬取），字段要求（序号、图片、电影名称、主演、时间、评分），并将信息写入文件中（具体参考 URL 地址：<http://maoyan.com/board/4>）。



> **解题提示**

1. 有道翻译信息的爬取可参考本周百度翻译信息爬取案例。
2. 58同城的租房信息获取，首先确定 URL 地址，编写爬虫程序，要使用正则表达式解析爬取信息。
3. 爬取猫眼电影中榜单栏目中 TOP100 榜的所有电影信息，首先确定 URL 地址（分页获取），使用正则解析每页的信息，并将信息写入文件。



> **批改标准**

1. 有道翻译信息爬取（30分）
2. 58同城的租房信息爬取（30分）
3. 猫眼电影 TOP100 榜单信息获取（30分）
4. 其他项（10分）—— 文件结构清晰、代码整洁、要求适量的注释



